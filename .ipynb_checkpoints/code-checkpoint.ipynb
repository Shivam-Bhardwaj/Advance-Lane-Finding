{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Advance Lane Finding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking random image for having image size\n",
    "img = mpimg.imread('camera_cal/calibration11.jpg')\n",
    "image_shape = img.shape\n",
    "\n",
    "nx = 9\n",
    "ny = 6\n",
    "\n",
    "objpoints = []\n",
    "imgpoints = []\n",
    "\n",
    "objp = np.zeros((nx*ny,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "\n",
    "fnames = glob.glob(\"camera_cal/calibration*.jpg\")\n",
    "\n",
    "for fname in fnames:\n",
    "    img = mpimg.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "    if ret:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        \n",
    "# use the object and image points to caliberate the camera and compute the camera matrix and distortion coefficients\n",
    "ret, cameraMatrix, distortionCoeffs, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, image_shape[:2],None,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distortion Correction Example\n",
    "\n",
    "We use the `cameraMatrix` and `distortionCoeffs` to undistort the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Distorted and undistorted images are stored side by side for comparision\n",
    "in folder named undistorted_inages. The name of the files are given such that\n",
    "upon pressing the arrow keys we can see the difference easily\n",
    "'''\n",
    "ctr = 0\n",
    "\n",
    "for fname in fnames:\n",
    "    img = mpimg.imread(fname)\n",
    "    cv2.imwrite(\"undistorted_images/%02ia.jpg\" %ctr,img)\n",
    "    undistorted = cv2.undistort(img, cameraMatrix, distortionCoeffs, None, cameraMatrix)\n",
    "    cv2.imwrite(\"undistorted_images/%02ib.jpg\" %ctr,undistorted)\n",
    "    ctr += 1   \n",
    "\n",
    "# Deleting used variables\n",
    "del ctr\n",
    "del fnames\n",
    "\n",
    "\n",
    "# img = mpimg.imread('camera_cal/calibration1.jpg')\n",
    "# undistorted = cv2.undistort(img, cameraMatrix, distortionCoeffs, None, cameraMatrix)\n",
    "# f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "# f.tight_layout()\n",
    "# ax1.imshow(img)\n",
    "# ax1.set_title('Original Image', fontsize=50)\n",
    "# ax2.imshow(undistorted)\n",
    "# ax2.set_title('Undistorted Image', fontsize=50)\n",
    "# plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradients and color transforms\n",
    "\n",
    "We use 2 kinds of gradient thresholds:\n",
    "\n",
    "1. Along the X axis.\n",
    "2. Directional gradient with thresholds of 30 and 90 degrees.\n",
    "\n",
    "This is done since the lane lines are more or less vertical.\n",
    "\n",
    "We then apply the following color thresholds:\n",
    "\n",
    "1. R & G channel thresholds so that yellow lanes are detected well.\n",
    "2. L channel threshold so that we don't take into account edges generated due to shadows.\n",
    "3. S channel threshold since it does a good job of separating out white & yellow lanes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thresholded_image(img):\n",
    "    \n",
    "    img = cv2.undistort(img, cameraMatrix, distortionCoeffs, None, cameraMatrix)\n",
    "    \n",
    "    # convert to gray scale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    height, width = gray.shape\n",
    "    \n",
    "    # apply gradient threshold on the horizontal gradient\n",
    "    sx_binary = abs_sobel_thresh(gray, 'x', 10, 200)\n",
    "    \n",
    "    # apply gradient direction threshold so that only edges closer to vertical are detected.\n",
    "    dir_binary = dir_threshold(gray, thresh=(np.pi/6, np.pi/2))\n",
    "    \n",
    "    # combine the gradient and direction thresholds.\n",
    "    combined_condition = ((sx_binary == 1) & (dir_binary == 1))\n",
    "    \n",
    "    # R & G thresholds so that yellow lanes are detected well.\n",
    "    color_threshold = 150\n",
    "    R = img[:,:,0]\n",
    "    G = img[:,:,1]\n",
    "    color_combined = np.zeros_like(R)\n",
    "    r_g_condition = (R > color_threshold) & (G > color_threshold)\n",
    "    \n",
    "    \n",
    "    # color channel thresholds\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    S = hls[:,:,2]\n",
    "    L = hls[:,:,1]\n",
    "    \n",
    "    # S channel performs well for detecting bright yellow and white lanes\n",
    "    s_thresh = (100, 255)\n",
    "    s_condition = (S > s_thresh[0]) & (S <= s_thresh[1])\n",
    "    \n",
    "    # We put a threshold on the L channel to avoid pixels which have shadows and as a result darker.\n",
    "    l_thresh = (120, 255)\n",
    "    l_condition = (L > l_thresh[0]) & (L <= l_thresh[1])\n",
    "\n",
    "    # combine all the thresholds\n",
    "    # A pixel should either be a yellowish or whiteish\n",
    "    # And it should also have a gradient, as per our thresholds\n",
    "    color_combined[(r_g_condition & l_condition) & (s_condition | combined_condition)] = 1\n",
    "    \n",
    "    # apply the region of interest mask\n",
    "    mask = np.zeros_like(color_combined)\n",
    "    region_of_interest_vertices = np.array([[0,height-1], [width/2, int(0.5*height)], [width-1, height-1]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, [region_of_interest_vertices], 1)\n",
    "    thresholded = cv2.bitwise_and(color_combined, mask)\n",
    "    \n",
    "    return thresholded\n",
    "    \n",
    "    \n",
    "    \n",
    "def abs_sobel_thresh(gray, orient='x', thresh_min=0, thresh_max=255):\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    max_value = np.max(abs_sobel)\n",
    "    binary_output = np.uint8(255*abs_sobel/max_value)\n",
    "    threshold_mask = np.zeros_like(binary_output)\n",
    "    threshold_mask[(binary_output >= thresh_min) & (binary_output <= thresh_max)] = 1\n",
    "    return threshold_mask\n",
    "\n",
    "def dir_threshold(gray, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Take the gradient in x and y separately\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    abs_sobel_x = np.absolute(sobel_x)\n",
    "    abs_sobel_y = np.absolute(sobel_y)\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient\n",
    "    direction = np.arctan2(abs_sobel_y,abs_sobel_x)\n",
    "    direction = np.absolute(direction)\n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    mask = np.zeros_like(direction)\n",
    "    mask[(direction >= thresh[0]) & (direction <= thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return mask\n",
    "\n",
    "del img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying binary thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Original and thresholded images are stored side by side for comparision\n",
    "in folder named test_images_output. The name of the files are given such that\n",
    "upon pressing the arrow keys we can see the difference easily\n",
    "'''\n",
    "images = []\n",
    "images = [cv2.imread(file) for file in glob.glob('test_images/*.jpg')]\n",
    "ctr = 0\n",
    "\n",
    "for i in range(5):\n",
    "    thresholded = get_thresholded_image(images[i])*255\n",
    "    cv2.imwrite(\"test_images_output/%02ia.jpg\" %ctr,thresholded)\n",
    "    cv2.imwrite(\"test_images_output/%02ib.jpg\" %ctr,images[i])\n",
    "    ctr += 1   \n",
    "\n",
    "\n",
    "# Plot the 2 images side by side\n",
    "# f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "# f.tight_layout()\n",
    "# ax1.imshow(img)\n",
    "# ax1.set_title('Original Image', fontsize=50)\n",
    "# ax2.imshow(thresholded, cmap='gray')\n",
    "# ax2.set_title('Thresholded Image', fontsize=50)\n",
    "# plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
